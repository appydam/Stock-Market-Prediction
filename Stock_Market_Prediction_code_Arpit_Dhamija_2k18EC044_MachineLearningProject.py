# -*- coding: utf-8 -*-
"""maruti_stockPrice_LSTM_____1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O74Re-qmUpT0efkWYiEEQXJ9SKiMvPM-

## Part-1 Data Preprocessing

Importing Liibraries
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

"""Importing dataset and creating training set(stocks till september 2020)"""

dataset = pd.read_csv('MARUTI.csv')
training_set = dataset.iloc[0:4284, 8:9].values   # till 31st august, test set me september ka month hoga

dataset.head()

plt.style.use("seaborn-talk")

training_set

# plot of training set
plt.plot(training_set)

# plot of the dataset (stocks till october 2020)
plt.plot(dataset.iloc[:,8:9].values)

plt.style.use("seaborn-talk")

plt.plot(training_set, c='b')

"""Creating Test set (stocks of *October* 2020)"""

testing_set = dataset.iloc[4284:, 8:9].values

testing_set

testing_set.shape      # 21 trading days in october

#ploting the test Set (october 2020)
plt.plot(testing_set)

training_set.shape

testing_set.shape

"""## Checking for Missing data

- Identify missing data in dataframes
- Treat (delete or impute) missing values if found
"""

print(dataset.shape)
print(dataset.info())

dataset.describe()

"""Identifying Missing Values

---


compute the total number of missing values in the data frame. You can calculate the number of missing values in each column by df.isnull().sum()
"""

dataset.isnull()

# summing up the missing values (column-wise)
dataset.isnull().sum()

"""There is no need to handle missing values, as there is only "Trades" whose all values are not in our dataset but we actually dont need Trade values as of now as our prediction is not dependent on Trade values. 
So, Just ignore handling this missing data

## Feature Scaling
"""

from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range = (0, 1))
training_set_scaled = sc.fit_transform(training_set)

"""training_set_scaled - it contains the new scaled training set whose values are between 0 and 1.
We have done normalisation 
![image.png](data:image/png;base64,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)
"""

training_set_scaled

"""## Creating a data structure with 80 timesteps and 1 output

Creating a data structure with 80 timesteps and 1 output. Model learns from past 80 days (appx 4 months) and predict the 81th day stock price by seeing the trends, model will basically create a pattern like what gonna happen after certain movements in stock market.
It is like doing the technical analysis of the stock.
"""

X_train = []
Y_train = []
for i in range(80, 4284):
    X_train.append(training_set_scaled[i-80:i, 0])
    Y_train.append(training_set_scaled[i, 0])
X_train, Y_train = np.array(X_train), np.array(Y_train)

X_train.shape

Y_train.shape

X_train.shape[0], X_train.shape[1]       # rows and columns

"""## Reshaping

Adding some more dimentionality to this data-structure (X-train) and that dimension is a unit, that is nuumber of predictors we can use to predict what we want. These predictors are **indicators**, like if we take only 1 indicator, as this financial problem has 'open prices' as a indicator which also defines the 'close prices' , so add dimension=1 to X_train.

Parameters of reshape function

X_train.shape[0] = no. of stocks / Batch Size


---


X_train.shape[1] = timesteps


---


1 = no. of indicators
"""

X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

X_train.shape[0] , X_train.shape[1] , X_train.shape[2]

"""# Part 2 - Building and Training the RNN

## Importing the Keras libraries and packages
"""

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Dropout
from keras.layers import GRU
import keras

keras.__version__

import tensorflow as tf

tf.__version__

"""## Initialising the RNN"""

regressor = Sequential()

"""## Adding the first LSTM layer and some Dropout regularisation"""

regressor.add(LSTM(units = 150,
                   return_sequences = True, 
                   input_shape = (X_train.shape[1], 1)
                   ))
regressor.add(Dropout(0.2))

"""## Adding a second LSTM layer and some Dropout regularisation"""

regressor.add(GRU(
    units = 150, 
    return_sequences = True
    ))
regressor.add(Dropout(0.2))

"""## Adding a third LSTM layer and some Dropout regularisation """

regressor.add(LSTM(
    units = 150,
    return_sequences = True
    ))
regressor.add(Dropout(0.2))



"""

```
# This is formatted as code
```

## Adding a forth LSTM layer and some Dropout regularisation"""

regressor.add(LSTM(units = 150))
regressor.add(Dropout(0.2))

"""## Adding the output layer """

regressor.add(Dense(units = 1))

"""## Compiling the RNN"""

regressor.compile(
    optimizer = 'adam',
    loss = 'mean_squared_error',
    metrics=['accuracy']
    )

Y_train.shape

"""## Fitting the RNN to the Training set """

regressor.fit(X_train, Y_train, epochs =500, batch_size = 32)

"""## Part 3 - Making the predictions and visualising the results

### Getting the real stock price
"""

real_stock_price = testing_set
len(real_stock_price)
# plot(real_stock_price)

dataset.iloc[0:4284, 8:9].shape

dataset['Close'].shape

dataset_total = pd.concat((dataset.iloc[0:4284, 8:9],dataset.iloc[4284:, 8:9]), axis = 0)

type(dataset_total['Close'])

type(dataset_total)

dataset['Close'][len(dataset) - len(real_stock_price) - 80:].values

dataset_total[len(dataset_total) - len(real_stock_price)  - 80:].values

"""### Getting the predicted stock price """

# dataset_total = pd.concat((dataset_train['close'], dataset_test['close']), axis = 0)
dataset_total = dataset['Close']
inputs = dataset_total[len(dataset_total) - len(real_stock_price) - 80:].values
inputs = inputs.reshape(-1,1)
inputs = sc.transform(inputs)
X_test = []
for i in range(80, 101):
    X_test.append(inputs[i-79:i+1, 0])
X_test = np.array(X_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
predicted_stock_price = regressor.predict(X_test)
predicted_stock_price = sc.inverse_transform(predicted_stock_price)

"""## Visualising the results"""

plt.plot(real_stock_price, color = 'red', label = 'Real Maruti Stock Price')
plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Maruti Stock Price')
plt.title('Maruti Stock Price Prediction')
plt.xlabel('Time')
plt.ylabel('Maruti Stock Price')
plt.legend()
plt.show()

import math
from sklearn.metrics import mean_squared_error
rmse = math.sqrt(mean_squared_error(real_stock_price, predicted_stock_price))

rmse

rmse/7000

rmse

loss = regressor.evaluate(X_train, Y_train, verbose=0)
print(loss)

9+8

regressor.summary()

